{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the analysis for the ConvX (a Udacity Capstone Project). Before starting, be sure to follow the instructions in the README for the project on github (https://github.com/justiniann/ConvX).\n",
    "\n",
    "This code was originally run on a personal desktop computer. The specs were...\n",
    "\n",
    "CPU: Intel i5 6600K, \n",
    "GPU: Nvidia 1060 GTX, \n",
    "RAM: 16GB\n",
    "\n",
    "I highly recommend that anyone attempting to run this code on the full dataset use hardware that is comparable or better.\n",
    "\n",
    "First, we need to load our base model. We will also define a few variables that we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.applications import ResNet50\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, confusion_matrix\n",
    "from convx_utils import *\n",
    "\n",
    "# This is our base model. We will use the weights and structure already known to be successful in other domains and\n",
    "#   adjust it to fit our current problem\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(512, 512, 3))\n",
    "\n",
    "target_image_size = (512, 512)\n",
    "batch_size = 32\n",
    "transfer_learning_epochs = 1\n",
    "fine_tuning_epochs = 1\n",
    "fine_tuning_layers_to_train = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define some paths that we will need later for saving various results as we run through our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following are directories used for reading/saving data\n",
    "RES_PATH = \"..{0}..{0}resources{0}\".format(os.path.sep)\n",
    "IMG_PATH = \"..{0}..{0}images{0}\".format(os.path.sep)\n",
    "BOTTLENECK_PATH = \"..{0}..{0}bottleneck{0}\".format(os.path.sep)\n",
    "SAVE_PATH = \"..{0}..{0}saved_models{0}\".format(os.path.sep)\n",
    "TRAIN_PATH = os.path.join(IMG_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(IMG_PATH, \"validation\")\n",
    "TEST_PATH = os.path.join(IMG_PATH, \"test\")\n",
    "\n",
    "model_name = \"convx_model\"  # The directory all data will be saved in will be named whatever this value is.\n",
    "models_save_directory = os.path.join(SAVE_PATH, model_name)\n",
    "build_dir_path(models_save_directory)  # build the directory structure we need for saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't included the top layer because we are going to build and train the top layer ourselves. This is known as transfer learning, and it is the first major step in training our model.\n",
    "\n",
    "Before starting that, however, we need to get a few variables we are going to need durring processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_files(root_dir):\n",
    "    return sum([len(files) for r, d, files in os.walk(root_dir)])\n",
    "\n",
    "def get_iterations_per_epoch(total_images, batch_size):\n",
    "    return np.ceil(total_images / batch_size)\n",
    "\n",
    "healthy_train_images = count_files(os.path.join(TRAIN_PATH, \"healthy\"))\n",
    "unhealthy_train_images = count_files(os.path.join(TRAIN_PATH, \"unhealthy\"))\n",
    "healthy_validation_images = count_files(os.path.join(VAL_PATH, \"healthy\"))\n",
    "unhealthy_validation_images = count_files(os.path.join(VAL_PATH, \"unhealthy\"))\n",
    "\n",
    "num_training_steps = get_iterations_per_epoch((healthy_train_images + unhealthy_train_images), batch_size)\n",
    "num_validation_steps = get_iterations_per_epoch((healthy_validation_images + unhealthy_validation_images), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency, we are going to get and save the bottleneck features for this model before we start with the transfer learning. By obtaining and saving these once, we can avoid having to run every image through the entire network durring every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_file_path = os.path.join(BOTTLENECK_PATH, model_name)\n",
    "train_bottleneck_file = os.path.join(bottleneck_file_path, \"train.npy\")\n",
    "validation_bottleneck_file = os.path.join(bottleneck_file_path, \"validation.npy\")\n",
    "    \n",
    "# Extract bottleneck features if they have not been already\n",
    "if not os.path.exists(bottleneck_file_path):\n",
    "    data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        TRAIN_PATH,\n",
    "        target_size=target_image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    build_dir_path(bottleneck_file_path)\n",
    "    bottleneck_features_train = base_model.predict_generator(train_generator, num_training_steps)\n",
    "    np.save(open(train_bottleneck_file, 'wb'), bottleneck_features_train)\n",
    "\n",
    "    validation_path_generator = data_generator.flow_from_directory(\n",
    "        VAL_PATH,\n",
    "        target_size=target_image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    bottleneck_features_validation = base_model.predict_generator(validation_path_generator, num_validation_steps)\n",
    "    np.save(open(validation_bottleneck_file, 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bottleneck features established, we can start transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80725 samples, validate on 8970 samples\n",
      "Epoch 1/1\n",
      "80725/80725 [==============================] - 22s - loss: 0.5383 - acc: 0.4619 - val_loss: 0.5334 - val_acc: 0.4666\n"
     ]
    }
   ],
   "source": [
    "def build_fully_connected_top_layer(connecting_shape):\n",
    "    top_layers = Sequential()\n",
    "    top_layers.add(Flatten(input_shape=connecting_shape))\n",
    "    top_layers.add(Dense(256, activation='relu'))\n",
    "    top_layers.add(Dropout(0.1))\n",
    "    top_layers.add(Dense(1, activation='sigmoid'))\n",
    "    return top_layers\n",
    "\n",
    "# load training data\n",
    "train_data = np.load(open(train_bottleneck_file, 'rb'))\n",
    "train_labels = np.array(([0] * healthy_train_images) + ([1] * unhealthy_train_images))\n",
    "\n",
    "# load validation data\n",
    "validation_data = np.load(open(validation_bottleneck_file, 'rb'))\n",
    "validation_labels = np.array([0] * healthy_validation_images + [1] * unhealthy_validation_images)\n",
    "\n",
    "top_layer = build_fully_connected_top_layer(train_data.shape[1:])\n",
    "\n",
    "top_layer.compile(loss='hinge',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "top_layer.fit(train_data, train_labels,\n",
    "              epochs=transfer_learning_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              verbose=1)\n",
    "\n",
    "top_layers_weights_path = os.path.join(models_save_directory, \"transfer_learning_weights.h5\")\n",
    "top_layer.save_weights(top_layers_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning has been completed and the results have been saved! We can now combine the base model with our newly trained top layer and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_layer = build_fully_connected_top_layer(base_model.output_shape[1:])\n",
    "top_layer.load_weights(top_layers_weights_path)\n",
    "\n",
    "convx_model = Model(inputs=base_model.input, outputs=top_layer(base_model.output))\n",
    "convx_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.SGD(momentum=0.95),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# TODO analyze that shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve our results by finetuning the model. Using the transfer learning model that we have already trained, we can 'unfreeze' a few of the layers from the base model. This will allow them to be trained, giving us an even better fit on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convx_model = Model(inputs=base_model.input, outputs=top_layer(base_model.output))\n",
    "\n",
    "for layer in convx_model.layers[:len(convx_model.layers) - fine_tuning_layers_to_train]:\n",
    "    layer.trainable = False\n",
    "\n",
    "convx_model.compile(loss='hinge',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "convx_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_training_steps,\n",
    "    epochs=fine_tuning_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_steps,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with open(os.path.join(models_save_directory, \"best_model.json\".format(model_name)), \"w\") as json_file:\n",
    "    json_file.write(convx_model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now been fine tuned and the training process is complete! Lets evaluate the results. While we are also going to look at accuracy, our primary metric of evaluation is going to be f-beta, with a beta score of three. With this, we will get to see which models fit the data well while giving more weight to good recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(models_save_directory, \"best_model.json\"), 'r') as model_file:\n",
    "    convx_model = model_from_json(model_file.read())\n",
    "    \n",
    "convx_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.SGD(momentum=0.95),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "healthy_test_images = count_files(os.path.join(TEST_PATH, \"healthy\"))\n",
    "unhealthy_test_images = count_files(os.path.join(TEST_PATH, \"unhealthy\"))\n",
    "test_iteration_count = get_iterations_per_epoch((healthy_test_images + unhealthy_test_images), batch_size)\n",
    "test_labels = np.array(([0] * healthy_test_images) + ([1] * unhealthy_test_images))\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "raw_predictions = convx_model.predict_generator(test_generator, test_iteration_count)\n",
    "predictions = np.round(raw_predictions)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "f3_score = fbeta_score(test_labels, predictions, 3)\n",
    "conf_matrix = confusion_matrix(test_labels, predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"F3 Score: {}\".format(f3_score))\n",
    "print(\"Confusion Matrix: \\n{}\".format(conf_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
