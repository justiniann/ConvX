{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the analysis for the ConvX (a Udacity Capstone Project). Before starting, be sure to follow the instructions in the README for the project on github (https://github.com/justiniann/ConvX).\n",
    "\n",
    "This code was originally run on a personal desktop computer. The specs were...\n",
    "\n",
    "CPU: Intel i5 6600K, \n",
    "GPU: Nvidia 1060 GTX, \n",
    "RAM: 16GB\n",
    "\n",
    "I highly recommend that anyone attempting to run this code on the full dataset use hardware that is comparable or better.\n",
    "\n",
    "The first step in this process is getting the data set up correctly. We start by running the preprocess function. This will turn the given Data_Entry_2017.csv file into a version we can use, as well as split the images in to train, test, and validation sets. The code for this is not shown, but you can find all of it in the convx_utils.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convx_utils import *\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training the data. First, we need to load our base model. We will also define a few variables that we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# This is our base model. We will use the weights and structure already known to be successful in other domains and\n",
    "#   adjust it to fit our current problem\n",
    "base_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(250, 250, 3))\n",
    "\n",
    "target_image_size = (250, 250)\n",
    "batch_size = 32\n",
    "transfer_learning_epochs = 200\n",
    "fine_tuning_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define some paths that we will need later for saving various results as we run through our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following are directories used for reading/saving data\n",
    "RES_PATH = \"..{0}..{0}resources{0}\".format(os.path.sep)\n",
    "IMG_PATH = \"..{0}..{0}images{0}\".format(os.path.sep)\n",
    "BOTTLENECK_PATH = \"..{0}..{0}bottleneck{0}\".format(os.path.sep)\n",
    "SAVE_PATH = \"..{0}..{0}saved_models{0}\".format(os.path.sep)\n",
    "TRAIN_PATH = os.path.join(IMG_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(IMG_PATH, \"validation\")\n",
    "TEST_PATH = os.path.join(IMG_PATH, \"test\")\n",
    "\n",
    "model_name = \"convx_model\"  # The directory all data will be saved in will be named whatever this value is.\n",
    "models_save_directory = os.path.join(SAVE_PATH, model_name)\n",
    "build_dir_path(models_save_directory)  # build the directory structure we need for saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't included the top layer because we are going to build and train the top layer ourselves. This is known as transfer learning, and it is the first major step in training our model.\n",
    "\n",
    "Before starting that, however, we need to get a few variables we are going to need durring processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_files(root_dir):\n",
    "    return sum([len(files) for r, d, files in os.walk(root_dir)])\n",
    "\n",
    "def get_iterations_per_epoch(total_images, batch_size):\n",
    "    return np.ceil(total_images / batch_size)\n",
    "\n",
    "healthy_train_images = count_files(os.path.join(TRAIN_PATH, \"healthy\"))\n",
    "unhealthy_train_images = count_files(os.path.join(TRAIN_PATH, \"unhealthy\"))\n",
    "healthy_validation_images = count_files(os.path.join(VAL_PATH, \"healthy\"))\n",
    "unhealthy_validation_images = count_files(os.path.join(VAL_PATH, \"unhealthy\"))\n",
    "\n",
    "num_training_steps = get_iterations_per_epoch((healthy_train_images + unhealthy_train_images), batch_size)\n",
    "num_validation_steps = get_iterations_per_epoch((healthy_validation_images + unhealthy_validation_images), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency, we are going to get and save the bottleneck features for this model before we start with the transfer learning. By obtaining and saving these once, we can avoid having to run every image through the entire network durring every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bottleneck_file = os.path.join(BOTTLENECK_PATH, model_name, \"train.npy\")\n",
    "validation_bottleneck_file = os.path.join(BOTTLENECK_PATH, model_name, \"validation.npy\")\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "bottleneck_features_train = model.predict_generator(train_generator, num_training_steps)\n",
    "build_dir_path(bottleneck_file_path)\n",
    "np.save(open(train_bottleneck_file, 'wb'), bottleneck_features_train)\n",
    "\n",
    "validation_path_generator = data_generator.flow_from_directory(\n",
    "    VALIDATION_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "bottleneck_features_validation = model.predict_generator(validation_path_generator, num_validation_steps)\n",
    "np.save(open(validation_bottleneck_file, 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bottleneck features established, we can start transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fully_connected_top_layer(connecting_shape):\n",
    "    top_layers = Sequential()\n",
    "    top_layers.add(Flatten(input_shape=connecting_shape))\n",
    "    top_layers.add(Dense(256, activation='relu'))\n",
    "    top_layers.add(Dropout(0.5))\n",
    "    top_layers.add(Dense(1, activation='sigmoid'))\n",
    "    return top_layers\n",
    "\n",
    "\n",
    "# load training data\n",
    "train_data = np.load(open(train_bottleneck_file, 'rb'))\n",
    "train_labels = np.array([0] * healthy_train_images + [1] * unhealthy_train_images)\n",
    "\n",
    "# load validation data\n",
    "validation_data = np.load(open(validation_bottleneck_file, 'rb'))\n",
    "validation_labels = np.array([0] * healthy_validation_images + [1] * unhealthy_validation_images)\n",
    "\n",
    "top_layer = build_fully_connected_top_layer(train_data.shape[1:])\n",
    "\n",
    "top_layer.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(momentum=0.95),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "top_layer.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              verbose=0)\n",
    "\n",
    "top_layers_weights_path = os.path.join(models_save_directory, \"transfer_learning_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning has been completed and the results have been saved! We can now combine the base model with our newly trained top layer and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_layer = build_fully_connected_top_layer(base_model.output_shape[1:])\n",
    "top_layer.load_weights(top_model_weights_path)\n",
    "\n",
    "convx_model = Model(inputs=base_model.input, outputs=top_layer(base_model.output))\n",
    "convx_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.SGD(momentum=0.95),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# TODO analyze that shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve our results by finetuning the model. Using the transfer learning model that we have already trained, we can 'unfreeze' a few of the layers from the base model. This will allow them to be trained, giving us an even better fit on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convx_model = Model(inputs=base_model.input, outputs=top_layer(base_model.output))\n",
    "\n",
    "for layer in model_for_finetune.layers[:len(model_for_finetune.layers) - layers_to_train]:\n",
    "    layer.trainable = False\n",
    "\n",
    "convx_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.SGD(momentum=0.95),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model_for_finetune.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_training_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_steps,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now been fine tuned and the training process is complete! Lets evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO analyze that shit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
